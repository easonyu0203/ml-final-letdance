{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-29T14:56:13.111603Z",
     "start_time": "2023-05-29T14:56:12.076317Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_transformer import MyTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# label\n",
    "label_feature = 'Danceability'\n",
    "\n",
    "# features\n",
    "dont_transform_features = ['Energy', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence']\n",
    "normal_transform_features = ['Tempo']\n",
    "power_transform_features = ['Loudness', 'Duration_ms', 'Stream', 'Views', 'Likes', 'Comments']\n",
    "categorical_features = ['Album_type', 'Key', 'Licensed', 'official_video']\n",
    "numerical_features=dont_transform_features + normal_transform_features + power_transform_features\n",
    "\n",
    "# all features\n",
    "features_columns = dont_transform_features + normal_transform_features + power_transform_features + categorical_features\n",
    "label_column = label_feature\n",
    "\n",
    "# import data\n",
    "train_df = pd.read_csv('data/train.csv')[features_columns + [label_column]]\n",
    "test_df = pd.read_csv('data/test.csv')[features_columns]\n",
    "test_ids = pd.read_csv('data/test.csv')['id']\n",
    "\n",
    "# init transformer\n",
    "my_transformer = MyTransformer(\n",
    "    all_features=features_columns,\n",
    "    categorical_features=categorical_features,\n",
    "    normal_transform_features=normal_transform_features,\n",
    "    power_transform_features=power_transform_features,\n",
    "    numerical_features=dont_transform_features + normal_transform_features + power_transform_features,\n",
    "    label_column=label_column,\n",
    ")\n",
    "\n",
    "# transform dataset\n",
    "train_X_df = my_transformer.features_fit_transform(train_df)\n",
    "train_Y_df = my_transformer.label_fit_transform(train_df)\n",
    "test_X_df = my_transformer.features_transform(test_df)\n",
    "\n",
    "# to numpy\n",
    "train_X = train_X_df.to_numpy()\n",
    "train_Y = train_Y_df.to_numpy()\n",
    "test_X = test_X_df.to_numpy()\n",
    "\n",
    "feature_size = train_X.shape[1]\n",
    "output_size = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [128, 64, 32, 16]\n",
    "epoch = 500\n",
    "batch_size = 128\n",
    "lr=0.00007\n",
    "validation_ratio = 0.2\n",
    "patience=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(train_X, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(train_Y, dtype=torch.float32)\n",
    "\n",
    "# Create TensorDatasets for training and validation\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Calculate the sizes of the train and validation datasets based on the split ratio\n",
    "train_size = int((1 - validation_ratio) * len(train_ds))\n",
    "val_size = len(train_ds) - train_size\n",
    "\n",
    "# Perform the random split\n",
    "train_ds, val_ds = random_split(train_ds, [train_size, val_size])\n",
    "\n",
    "class DeepLinearModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(DeepLinearModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.layers = nn.Sequential()\n",
    "        sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        for i in range(len(sizes) - 1):\n",
    "            self.layers.add_module(f\"linear_{i}\", nn.Linear(sizes[i], sizes[i+1]))\n",
    "            if i < len(sizes) - 2:\n",
    "                self.layers.add_module(f\"relu_{i}\", nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.functional.l1_loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = nn.functional.l1_loss(y_hat, y)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=False)\n",
    "        return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# Define the ModelCheckpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss')\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "# Create a PyTorch Lightning Trainer\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "trainer = pl.Trainer(max_epochs=epoch, callbacks=[lr_monitor, checkpoint_callback, early_stop_callback])\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Initialize the model\n",
    "model = DeepLinearModel(input_size=feature_size, hidden_sizes=hidden_sizes, output_size=output_size)\n",
    "\n",
    "# Train the model using PyTorch Lightning\n",
    "trainer.fit(model, train_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.8281250335858203\n",
      "validation Loss: 1.7265625384752639\n"
     ]
    }
   ],
   "source": [
    "# Access the best model based on the validation loss\n",
    "best_model = trainer.checkpoint_callback.best_model_path\n",
    "\n",
    "best_model = DeepLinearModel.load_from_checkpoint(best_model)\n",
    "\n",
    "def calculate_training_loss(best_model, ds, batch_size, my_transformer):\n",
    "    # Set the best model to evaluation mode\n",
    "    best_model.eval()\n",
    "\n",
    "    # Create a DataLoader for the training dataset\n",
    "    train_dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Calculate the training loss using the best model\n",
    "    train_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in train_dl:\n",
    "            x, y = batch\n",
    "            x, y = x.to(\"mps\"), y.to(\"mps\")\n",
    "            y_hat = best_model(x)\n",
    "            y_hat, y = y_hat.cpu(), y.cpu()\n",
    "            # Convert to numpy\n",
    "            y_hat, y = y_hat.numpy(), y.numpy()\n",
    "            y_hat, y = my_transformer.inverse_label_transform(y_hat.reshape(-1)), my_transformer.inverse_label_transform(y.reshape(-1))\n",
    "            y_hat = np.clip(np.round(y_hat), 0, 9)\n",
    "            loss = nn.functional.l1_loss(torch.tensor([y_hat]), torch.tensor([y]))\n",
    "            train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            break\n",
    "\n",
    "    train_loss /= num_batches\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "train_loss = calculate_training_loss(best_model, train_ds, batch_size, my_transformer)\n",
    "print(\"Training Loss:\", train_loss)\n",
    "train_loss = calculate_training_loss(best_model, val_ds, batch_size, my_transformer)\n",
    "print(\"validation Loss:\", train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tensor = torch.tensor(test_X, dtype=torch.float32)\n",
    "ids = torch.tensor(test_ids, dtype=torch.int32)\n",
    "\n",
    "test_ds = TensorDataset(ids, x_test_tensor)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "ids, preds = [], []\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dl:\n",
    "        i, x = batch\n",
    "        ids.append(i.numpy())\n",
    "        \n",
    "        y_hat = best_model(x.to(\"mps\")).cpu().numpy()\n",
    "        y_hat = my_transformer.inverse_label_transform(y_hat.reshape(-1))\n",
    "        y_hat = np.clip(np.round(y_hat), 0, 9)\n",
    "        preds.append(y_hat)\n",
    "\n",
    "ids = np.concatenate(ids)\n",
    "preds = np.concatenate(preds)\n",
    "\n",
    "submission_df = pd.DataFrame({'id': ids, 'Danceability': preds})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 1.000e+00,\n",
       "        1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
       "        2.000e+00, 1.000e+00, 1.000e+00, 4.000e+00, 8.000e+00, 3.000e+00,\n",
       "        3.000e+00, 6.000e+00, 8.000e+00, 9.000e+00, 2.200e+01, 1.700e+01,\n",
       "        2.800e+01, 4.500e+01, 7.100e+01, 6.063e+03]),\n",
       " array([-8.35857762e+13, -8.27499185e+13, -8.19140609e+13, -8.10782032e+13,\n",
       "        -8.02423455e+13, -7.94064878e+13, -7.85706302e+13, -7.77347725e+13,\n",
       "        -7.68989148e+13, -7.60630571e+13, -7.52271994e+13, -7.43913418e+13,\n",
       "        -7.35554841e+13, -7.27196264e+13, -7.18837687e+13, -7.10479110e+13,\n",
       "        -7.02120534e+13, -6.93761957e+13, -6.85403380e+13, -6.77044803e+13,\n",
       "        -6.68686227e+13, -6.60327650e+13, -6.51969073e+13, -6.43610496e+13,\n",
       "        -6.35251919e+13, -6.26893301e+13, -6.18534724e+13, -6.10176147e+13,\n",
       "        -6.01817570e+13, -5.93458994e+13, -5.85100417e+13, -5.76741840e+13,\n",
       "        -5.68383263e+13, -5.60024686e+13, -5.51666110e+13, -5.43307533e+13,\n",
       "        -5.34948956e+13, -5.26590379e+13, -5.18231803e+13, -5.09873226e+13,\n",
       "        -5.01514649e+13, -4.93156072e+13, -4.84797495e+13, -4.76438919e+13,\n",
       "        -4.68080342e+13, -4.59721765e+13, -4.51363188e+13, -4.43004611e+13,\n",
       "        -4.34646035e+13, -4.26287458e+13, -4.17928881e+13, -4.09570304e+13,\n",
       "        -4.01211728e+13, -3.92853151e+13, -3.84494574e+13, -3.76135997e+13,\n",
       "        -3.67777420e+13, -3.59418844e+13, -3.51060267e+13, -3.42701690e+13,\n",
       "        -3.34343113e+13, -3.25984536e+13, -3.17625960e+13, -3.09267362e+13,\n",
       "        -3.00908785e+13, -2.92550208e+13, -2.84191632e+13, -2.75833055e+13,\n",
       "        -2.67474478e+13, -2.59115901e+13, -2.50757324e+13, -2.42398748e+13,\n",
       "        -2.34040171e+13, -2.25681594e+13, -2.17323017e+13, -2.08964441e+13,\n",
       "        -2.00605864e+13, -1.92247287e+13, -1.83888710e+13, -1.75530133e+13,\n",
       "        -1.67171557e+13, -1.58812980e+13, -1.50454393e+13, -1.42095816e+13,\n",
       "        -1.33737239e+13, -1.25378662e+13, -1.17020085e+13, -1.08661509e+13,\n",
       "        -1.00302932e+13, -9.19443551e+12, -8.35857783e+12, -7.52271963e+12,\n",
       "        -6.68686195e+12, -5.85100427e+12, -5.01514659e+12, -4.17928892e+12,\n",
       "        -3.34343098e+12, -2.50757330e+12, -1.67171549e+12, -8.35857744e+11,\n",
       "         1.11682880e+00]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_tensor = torch.tensor(test_X, dtype=torch.float32)\n",
    "ids = torch.tensor(test_ids, dtype=torch.int32)\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = best_model(x_test_tensor.to(\"mps\")).cpu().numpy()\n",
    "# preds = my_transformer.inverse_label_transform(preds.reshape(-1))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(preds, bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
