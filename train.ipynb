{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer, FunctionTransformer\n",
    "import xgboost as xgb\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_feature = 'Danceability'\n",
    "numerical_features = ['Energy', 'Loudness', 'Speechiness', 'Acousticness',\n",
    "                      'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Duration_ms', 'Stream',\n",
    "                      'Views', 'Likes', 'Comments']\n",
    "\n",
    "categorical_features = ['Album_type', 'Key', 'Licensed', 'official_video']\n",
    "\n",
    "string_features = [\n",
    "    'Track', 'Artist', 'Composer', 'Album', 'Title', 'Channel', 'Description'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define used features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "label_feature = 'Danceability'\n",
    "\n",
    "# features\n",
    "dont_transform_features = ['Energy', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence']\n",
    "normal_transform_features = ['Tempo']\n",
    "power_transform_features = ['Loudness', 'Duration_ms', 'Stream', 'Views', 'Likes', 'Comments']\n",
    "categorical_features = ['Album_type', 'Key', 'Licensed', 'official_video']\n",
    "\n",
    "\n",
    "features_columns = dont_transform_features + normal_transform_features + power_transform_features + categorical_features\n",
    "label_column = label_feature\n",
    "train_df = train_df[features_columns + [label_column]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform features and label\n",
    "normal_transformer = StandardScaler()\n",
    "skewed_transformer = PowerTransformer()\n",
    "min_max_transformer = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform features and label\n",
    "normal_transformer = StandardScaler()\n",
    "power_transformer = PowerTransformer()\n",
    "label_transformer = MinMaxScaler()\n",
    "\n",
    "# transform features & label\n",
    "train_df[normal_transform_features] = normal_transformer.fit_transform(train_df[normal_transform_features])\n",
    "train_df[power_transform_features] = power_transformer.fit_transform(train_df[power_transform_features])\n",
    "train_df[label_column] = label_transformer.fit_transform(train_df[[label_column]])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "train_df = pd.get_dummies(train_df, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6895748398369248\n",
      "1.7355853232382061\n",
      "1.7018054746651137\n",
      "1.7507280139778685\n",
      "1.8025626092020968\n",
      "1.6860803727431566\n",
      "1.7402446126965638\n",
      "1.7067559697146186\n",
      "1.7623762376237624\n",
      "1.8066394874781595\n",
      "1.6624927198602213\n",
      "1.6878276062900408\n",
      "1.6569598136284216\n",
      "1.717239370995923\n",
      "1.7609202096680256\n",
      "1.662201514269074\n",
      "1.6942341292952825\n",
      "1.672976121141526\n",
      "1.730343622597554\n",
      "1.7550960978450787\n",
      "1.6482236458940012\n",
      "1.678800232964473\n",
      "1.6575422248107163\n",
      "1.7041351193942924\n",
      "1.7376237623762376\n",
      "1.6645311589982528\n",
      "1.6887012230634828\n",
      "1.6566686080372743\n",
      "1.7076295864880606\n",
      "1.745486313337216\n",
      "1.6243447874199184\n",
      "1.6645311589982528\n",
      "1.6327897495631916\n",
      "1.692195690157251\n",
      "1.720442632498544\n",
      "1.6435643564356435\n",
      "1.6706464764123472\n",
      "1.63075131042516\n",
      "1.6901572510192195\n",
      "1.7417006406523006\n",
      "1.648806057076296\n",
      "1.6694816540477577\n",
      "1.6368666278392545\n",
      "1.6750145602795574\n",
      "1.7457775189283635\n",
      "1.6421083284799067\n",
      "1.684041933605125\n"
     ]
    }
   ],
   "source": [
    "X, Y = train_df.drop(columns=[label_column]), train_df[label_column]\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "def custom_scorer(y_true, y_pred):\n",
    "    y_pred = label_transformer.inverse_transform([y_pred])\n",
    "    y_pred = np.clip(np.round(y_pred), 0, 9)\n",
    "    y_true = label_transformer.inverse_transform([y_true])\n",
    "    print(mean_absolute_error(y_true, y_pred))\n",
    "    return -mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Create an instance of the HistGradientBoostingRegressor\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "scoring = make_scorer(custom_scorer)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=scoring, cv=5)\n",
    "grid_search.fit(X, Y)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Create a new instance of HistGradientBoostingRegressor with the best parameters\n",
    "model = HistGradientBoostingRegressor(**best_params)\n",
    "\n",
    "# Fit the best HistGradientBoostingRegressor on the entire dataset\n",
    "model = model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "ids = test_df['id']\n",
    "test_df = test_df[features_columns]\n",
    "test_df = pd.get_dummies(test_df, columns=categorical_features)\n",
    "\n",
    "# Transform the test data\n",
    "test_df[normal_transform_features] = normal_transformer.transform(test_df[normal_transform_features])\n",
    "test_df[power_transform_features] = power_transformer.transform(test_df[power_transform_features])\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(test_df)\n",
    "test_predictions = label_transformer.inverse_transform([test_predictions])\n",
    "test_predictions = np.clip(np.round(test_predictions), 0, 9)\n",
    "test_predictions = test_predictions.astype(int).reshape(-1)\n",
    "\n",
    "# Prepare the submission dataframe\n",
    "submission_df = pd.DataFrame({'id': ids, 'Danceability': test_predictions})\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
